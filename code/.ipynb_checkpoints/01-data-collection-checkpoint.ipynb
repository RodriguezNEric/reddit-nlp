{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Reddit data scraping\n",
    "\n",
    "## Part 1 - Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import datetime as dt\n",
    "import math\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pushshift url template\n",
    "# https://api.pushshift.io/reddit/search/submission?subreddit={}&after={}&before={}&size={}\n",
    "# max request size is 100!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping data from mentalhealth subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subreddit to be scraped\n",
    "subreddit = 'mentalhealth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time parameters\n",
    "after = 1611140400 # epoch timestamp for 1/20/2021 6am GMT -04:00 DST\n",
    "before = 1618912800 # epoch timestamp for 4/20/2021 6am GMT -04:00 DST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n"
     ]
    }
   ],
   "source": [
    "# h/t stack overflow \n",
    "# Set up dict for info to collect\n",
    "posts_data = {'created_utc':[],\n",
    "              'url':[],\n",
    "              'full_link':[],\n",
    "              'id':[],\n",
    "              'num_comments':[],\n",
    "              'title':[],\n",
    "              'selftext':[],\n",
    "              'subreddit':[]\n",
    "              }\n",
    "\n",
    "headers = {'User-agent': 'Reddit Post Collector'}\n",
    "\n",
    "# Set up function to return submission data\n",
    "def get_submissions(**kwargs):\n",
    "    res = requests.get(\"https://api.pushshift.io/reddit/submission/search/\",\n",
    "                       params=kwargs,\n",
    "                       headers=headers)\n",
    "    if res.status_code == 200:\n",
    "        data = res.json()\n",
    "        return data['data']\n",
    "    else:\n",
    "        print(res.status_code)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Collect up to 2,000 posts as long as there are posts to collect\n",
    "while True and len(set(posts_data['created_utc'])) <= 1900:\n",
    "    print(count)\n",
    "    count += 1*100\n",
    "    \n",
    "    posts = get_submissions(subreddit=subreddit,\n",
    "                            size=100,\n",
    "                            after=after, #pulls submissions only after this date\n",
    "                            before=before, #pulls submissions only before this date\n",
    "                            sort='asc', #returns data with earliest date first\n",
    "                            sort_type='created_utc')\n",
    "    if not posts:\n",
    "        break\n",
    "\n",
    "    for post in posts:\n",
    "        # Keep track of position for the next call in while loop\n",
    "        after = post['created_utc']\n",
    "\n",
    "        # Append info to posts_data dict\n",
    "        posts_data['created_utc'].append(post['created_utc'])\n",
    "        posts_data['url'].append(post['url'])\n",
    "        posts_data['full_link'].append(post['full_link'])\n",
    "        posts_data['id'].append(post['id'])\n",
    "        posts_data['num_comments'].append(post['num_comments'])\n",
    "        posts_data['title'].append(post['title'])\n",
    "        posts_data['selftext'].append(post['selftext'])\n",
    "        posts_data['subreddit'].append(post['subreddit'])\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "# Save posts to dataframe\n",
    "posts_data = pd.DataFrame(posts_data)\n",
    "\n",
    "# Create `timestamp` column with `created_utc` translated into readable time\n",
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "\n",
    "_timestamp = posts_data['created_utc'].apply(get_date)\n",
    "posts_data = posts_data.assign(timestamp = _timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>url</th>\n",
       "      <th>full_link</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1613341829</td>\n",
       "      <td>https://www.reddit.com/r/mentalhealth/comments...</td>\n",
       "      <td>https://www.reddit.com/r/mentalhealth/comments...</td>\n",
       "      <td>ljz25o</td>\n",
       "      <td>4</td>\n",
       "      <td>really quite sad and lonely</td>\n",
       "      <td>I feel extremely lonely and sad. I’ve felt lik...</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>2021-02-14 17:30:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1613342047</td>\n",
       "      <td>https://www.reddit.com/r/mentalhealth/comments...</td>\n",
       "      <td>https://www.reddit.com/r/mentalhealth/comments...</td>\n",
       "      <td>ljz4p5</td>\n",
       "      <td>6</td>\n",
       "      <td>always feel like i'm being watched</td>\n",
       "      <td>which sounds kind of odd. it's... not exactly ...</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>2021-02-14 17:34:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1613342047</td>\n",
       "      <td>https://www.reddit.com/r/mentalhealth/comments...</td>\n",
       "      <td>https://www.reddit.com/r/mentalhealth/comments...</td>\n",
       "      <td>ljz4p6</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I inform my parent on how to support m...</td>\n",
       "      <td>My father is having difficulties understanding...</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>2021-02-14 17:34:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1613342356</td>\n",
       "      <td>https://www.reddit.com/r/mentalhealth/comments...</td>\n",
       "      <td>https://www.reddit.com/r/mentalhealth/comments...</td>\n",
       "      <td>ljz882</td>\n",
       "      <td>2</td>\n",
       "      <td>Discrimination of Young People with Mental Hea...</td>\n",
       "      <td>Hello, I am currently researching stigmas asso...</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>2021-02-14 17:39:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1613342754</td>\n",
       "      <td>https://www.reddit.com/r/mentalhealth/comments...</td>\n",
       "      <td>https://www.reddit.com/r/mentalhealth/comments...</td>\n",
       "      <td>ljzcnn</td>\n",
       "      <td>2</td>\n",
       "      <td>I haven't told anyone this before.</td>\n",
       "      <td>\\n\\nI am a full-grown adult (33 years old) ...</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>2021-02-14 17:45:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      created_utc                                                url  \\\n",
       "1995   1613341829  https://www.reddit.com/r/mentalhealth/comments...   \n",
       "1996   1613342047  https://www.reddit.com/r/mentalhealth/comments...   \n",
       "1997   1613342047  https://www.reddit.com/r/mentalhealth/comments...   \n",
       "1998   1613342356  https://www.reddit.com/r/mentalhealth/comments...   \n",
       "1999   1613342754  https://www.reddit.com/r/mentalhealth/comments...   \n",
       "\n",
       "                                              full_link      id  num_comments  \\\n",
       "1995  https://www.reddit.com/r/mentalhealth/comments...  ljz25o             4   \n",
       "1996  https://www.reddit.com/r/mentalhealth/comments...  ljz4p5             6   \n",
       "1997  https://www.reddit.com/r/mentalhealth/comments...  ljz4p6             6   \n",
       "1998  https://www.reddit.com/r/mentalhealth/comments...  ljz882             2   \n",
       "1999  https://www.reddit.com/r/mentalhealth/comments...  ljzcnn             2   \n",
       "\n",
       "                                                  title  \\\n",
       "1995                        really quite sad and lonely   \n",
       "1996                 always feel like i'm being watched   \n",
       "1997  How can I inform my parent on how to support m...   \n",
       "1998  Discrimination of Young People with Mental Hea...   \n",
       "1999                 I haven't told anyone this before.   \n",
       "\n",
       "                                               selftext     subreddit  \\\n",
       "1995  I feel extremely lonely and sad. I’ve felt lik...  mentalhealth   \n",
       "1996  which sounds kind of odd. it's... not exactly ...  mentalhealth   \n",
       "1997  My father is having difficulties understanding...  mentalhealth   \n",
       "1998  Hello, I am currently researching stigmas asso...  mentalhealth   \n",
       "1999     \\n\\nI am a full-grown adult (33 years old) ...  mentalhealth   \n",
       "\n",
       "               timestamp  \n",
       "1995 2021-02-14 17:30:29  \n",
       "1996 2021-02-14 17:34:07  \n",
       "1997 2021-02-14 17:34:07  \n",
       "1998 2021-02-14 17:39:16  \n",
       "1999 2021-02-14 17:45:54  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "filetime = time.strftime(\"%y%m%d_%H%M%S\", time.localtime())\n",
    "posts_data.to_csv('/Users/ericrodriguez/Projects/Submissions/Projects/project_3-nlp_reddit/data/{}_{}.csv'.format(subreddit, filetime), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping data from CoronavirusUS subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subreddit to be scraped\n",
    "subreddit = 'CoronavirusUS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h/t stack overflow \n",
    "# Set up dict for info to collect\n",
    "posts_data = {'created_utc':[],\n",
    "              'url':[],\n",
    "              'full_link':[],\n",
    "              'id':[],\n",
    "              'num_comments':[],\n",
    "              'title':[],\n",
    "              'selftext':[],\n",
    "              'subreddit':[]\n",
    "              }\n",
    "\n",
    "headers = {'User-agent': 'Reddit Post Collector'}\n",
    "\n",
    "# Set up function to return submission data\n",
    "def get_submissions(**kwargs):\n",
    "    res = requests.get(\"https://api.pushshift.io/reddit/submission/search/\",\n",
    "                       params=kwargs,\n",
    "                       headers=headers)\n",
    "    if res.status_code == 200:\n",
    "        data = res.json()\n",
    "        return data['data']\n",
    "    else:\n",
    "        print(res.status_code)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Collect up to 2,000 posts as long as there are posts to collect\n",
    "while True and len(set(posts_data['created_utc'])) <= 1900:\n",
    "    print(count)\n",
    "    count += 1*100\n",
    "    \n",
    "    posts = get_submissions(subreddit=subreddit,\n",
    "                            size=100,\n",
    "                            after=after, #pulls submissions only after this date\n",
    "                            before=before, #pulls submissions only before this date\n",
    "                            sort='asc', #returns data with earliest date first\n",
    "                            sort_type='created_utc')\n",
    "    if not posts:\n",
    "        break\n",
    "\n",
    "    for post in posts:\n",
    "        # Keep track of position for the next call in while loop\n",
    "        after = post['created_utc']\n",
    "\n",
    "        # Append info to posts_data dict\n",
    "        posts_data['created_utc'].append(post['created_utc'])\n",
    "        posts_data['url'].append(post['url'])\n",
    "        posts_data['full_link'].append(post['full_link'])\n",
    "        posts_data['id'].append(post['id'])\n",
    "        posts_data['num_comments'].append(post['num_comments'])\n",
    "        posts_data['title'].append(post['title'])\n",
    "        posts_data['selftext'].append(post['selftext'])\n",
    "        posts_data['subreddit'].append(post['subreddit'])\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "# Save posts to dataframe\n",
    "posts_data = pd.DataFrame(posts_data)\n",
    "\n",
    "# Create `timestamp` column with `created_utc` translated into readable time\n",
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "\n",
    "_timestamp = posts_data['created_utc'].apply(get_date)\n",
    "posts_data = posts_data.assign(timestamp = _timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "filetime = time.strftime(\"%y%m%d_%H%M%S\", time.localtime())\n",
    "posts_data.to_csv('/Users/ericrodriguez/Projects/Submissions/Projects/project_3-nlp_reddit/data/{}_{}.csv'.format(subreddit, filetime), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
